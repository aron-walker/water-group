{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d5d38e-fef8-4653-ab43-71738b257ba5",
   "metadata": {},
   "source": [
    "### Building a Bridge: From Fires to People\n",
    "\n",
    "The goals of this notebook are to:\n",
    "\n",
    "1. determine the cumulative fraction of each basin that has burned\n",
    "2. determine the fraction of each basin's upstream watershed that has burned\n",
    "3. map those values to flood hazard zones\n",
    "4. map enhanced flood hazards to census tracts\n",
    "5. integrate enhanced flood hazard and social vulnerability to prioritize census tracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165dbc5d-8e21-4156-ae8e-19695e6a88ef",
   "metadata": {},
   "source": [
    "#### Step 0: Step Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7efda39-fa7c-4c30-ac91-2e73ceb0d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9056c841-22de-4362-84ff-4c51673e0d55",
   "metadata": {},
   "source": [
    "Address a Conda <--> PROJ error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a7ad2e-0215-4524-a4c5-2b8d50ee058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://gis.stackexchange.com/questions/364421/how-to-make-proj-work-via-anaconda-in-google-colab\n",
    "import os; os.environ['PROJ_LIB'] = '/path/to/env/share/proj'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5c3a26-ed40-4010-9e1a-37093fb50b5f",
   "metadata": {},
   "source": [
    "Import fire data, changing to a common coordiante system that supports measurement. Full credit to Matt for finding the fire data and converting it to `.geojson`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d4e8d2-0a95-4fa6-b9dd-a560d5dc23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=gpd.read_file(\"data/LAC_fires.geojson\").to_crs(epsg=6933)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d2c893-20f5-47b8-be9e-b4bd79cb1064",
   "metadata": {},
   "source": [
    "Next, import hydrologica basin data. This global data set is too big to import and needs a bounding box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e880c0a-c209-41b8-af2c-a861b8d0efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = (-118.9441,32.8065,-117.6447,34.8227)\n",
    "# Source: https://observablehq.com/@rdmurphy/u-s-county-bounding-boxes-by-state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d1f628-f692-4a23-998c-84667908bc4e",
   "metadata": {},
   "source": [
    "Now it can be imported; select level 12 to get maximum spatial resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2bf7da-1484-4a27-8998-8d3baea0a788",
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "'/vsizip/data/BasinATLAS_Data_v10.gdb.zip' does not exist in the file system, and is not recognized as a supported dataset name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mfiona/_shim.pyx:83\u001b[0m, in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: '/vsizip/data/BasinATLAS_Data_v10.gdb.zip' does not exist in the file system, and is not recognized as a supported dataset name.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m b\u001b[38;5;241m=\u001b[39m\u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/BasinATLAS_Data_v10.gdb.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFileGDB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBasinATLAS_v10_lev12\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/geopandas/io/file.py:259\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m     path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_fiona\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_pyogrio(\n\u001b[1;32m    264\u001b[0m         path_or_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    265\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/geopandas/io/file.py:303\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[1;32m    304\u001b[0m         crs \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;66;03m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fiona/env.py:408\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local\u001b[38;5;241m.\u001b[39m_env:\n\u001b[0;32m--> 408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fiona/__init__.py:264\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 264\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_drivers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m schema:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;66;03m# Make an ordered dict of schema properties.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fiona/collection.py:162\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:540\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_shim.pyx:90\u001b[0m, in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: '/vsizip/data/BasinATLAS_Data_v10.gdb.zip' does not exist in the file system, and is not recognized as a supported dataset name."
     ]
    }
   ],
   "source": [
    "b=gpd.read_file(\"data/BasinATLAS_Data_v10.gdb.zip\", driver='FileGDB', layer='BasinATLAS_v10_lev12',bbox=bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393dfb59-e05f-46ea-9d75-44ddcdc23f72",
   "metadata": {},
   "source": [
    "As with fire data, change the coordinates to a common set that supports measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04081c5e-8d50-4880-ae03-c5ca6c0237d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.to_crs(6933)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5212ff16-e2e9-4658-bc8f-8e0feab31b7a",
   "metadata": {},
   "source": [
    "From earlier basin exploration, we know we want to remove the two basins corresponding to islands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1043c4-1b90-49c8-b653-76808993750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b[b['HYBAS_ID']!=7120055730]\n",
    "b = b[b['HYBAS_ID']!=7120055740]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f96ec-68cb-48f0-902e-10d7c1a252b5",
   "metadata": {},
   "source": [
    "#### Step 1: Determine the cumulative fraction of each basin that has been burned\n",
    "\n",
    "What we want to do now is use the `intersection` function in geopandas to find the area of each fire-to-basin overlap and sum those areas for each basin. For example, if a basin was 20% burned by one fire and 15% burned by another, we want the outcome to be 35% -- regardless of whether or not the two fires themselves overlap (because, probably, they happened far enough apart to have \"independent\" impacts on runoff. A more advanced version would add a recovery function.\n",
    "\n",
    "To do this, we transform both geodataframes into lists with one basin (or fire) per list entry and then use \"list comprehension\" syntax to map the pairs through the intersection calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd7fa31-904e-4a31-92de-74ac6b8e5c78",
   "metadata": {},
   "source": [
    "Use a ***loop*** to create a list \"basins\" with one entry per basin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf9b6e7-d2e2-4702-a505-5974c4b67701",
   "metadata": {},
   "outputs": [],
   "source": [
    "basins = []\n",
    "for i in list(range(0,b.shape[0])):\n",
    "    basins.append([b.iloc[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de15e2-337f-45f6-965c-e8b555a8bffb",
   "metadata": {},
   "source": [
    "Create a list \"fires\" with one entry per fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4353f1b4-396e-441a-a734-ab8a6973b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fires = []\n",
    "for i in list(range(0,f.shape[0])):\n",
    "    fires.append([f.iloc[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65868d8c-84fe-4428-991b-7a5723e28b1f",
   "metadata": {},
   "source": [
    "The next block is the heart of this section of code. These are three nested functions, that iterate through two lists of geographies, calculating the area of their intersection and summing them for each unit of one of the lists. Really this is two ***loops***, just written with more concise syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecaed60-dc63-4557-8e57-c5ab2ade0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(a,b):\n",
    "    return a[0][\"geometry\"].intersection(b[0][\"geometry\"]).area\n",
    "def f2(b,aa):\n",
    "    return sum([f1(a,b) for a in aa])\n",
    "def f3(aa,bb):\n",
    "    return [f2(b,aa) for b in bb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b4120-d197-41e8-8923-0693116686e4",
   "metadata": {},
   "source": [
    "Now we can use this set of functions to compute the area of fire intersection in each basin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b177aa53-c474-4c92-8709-c7b6cb13bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "burned=f3(fires,basins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2979dd-4c06-4e29-9dc1-54b6f073f531",
   "metadata": {},
   "source": [
    "Now `burned` is a list with one entry per basin, with the entry being the cumulative burned area. Let's make sure there are the right number of entries (the following three numbers should be the same):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae499dc-088e-4e03-ad50-c135f97455ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(burned))\n",
    "print(len(basins))\n",
    "print(b.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724f503-ba43-4ec1-800e-8772567d87bc",
   "metadata": {},
   "source": [
    "Next, we want to assign each cumulative burned area to each basin, by creating a column in the geodataframe 'b' with values equal to the list 'burned'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a0780-5314-4883-837d-0bef7f6c01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"burnt\"] = burned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303cb363-3992-4044-af31-9d62fe1ad7b1",
   "metadata": {},
   "source": [
    "We show that this worked by plotting with color for cumulative burned fraction; save figure for presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8a5bd-e3c4-43e5-b0e3-427eceed16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.plot(column=b[\"burnt\"])\n",
    "plt.savefig(\"burnt.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f2e03-4b2c-4a7c-ba6a-f486eab9936e",
   "metadata": {},
   "source": [
    "Also, noting that this looks correct -- the fires are in the hills!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa0b73-8e4d-46db-b3f2-a71787729ae7",
   "metadata": {},
   "source": [
    "#### Step 2: Calculate for each basin the total burnt area in the basin and *upstream* of the basin.\n",
    "\n",
    "The basin data already have a column providing the immediate *downstream* basin for each basin. For each basin, we need to identiy the immediate *upstream* basin(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fbd1bd-2052-4f4c-a0b4-bcd86dfead3d",
   "metadata": {},
   "source": [
    "First, we make a list where the nth entry is the *downstream* basin for for basin n. To do this, we create a function to look up the downstream basin (working in the basins list, not the geodataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e45ff2-5eac-4dec-979c-35ed4d69ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_down(basin):\n",
    "    return basin[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e627a08a-bf78-4875-ab66-0e4de8a2e743",
   "metadata": {},
   "source": [
    "Next, we apply that function to all basins in the basins list, returning a list of downstream basins. For anyone looking for loops, note that this is another ***loop***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c478555-316f-4e5b-92ef-9e1c5c09bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "downs = [get_down(basin) for basin in basins]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8d500-d483-4b36-871f-2d56a25914e0",
   "metadata": {},
   "source": [
    "Now we need a function to look up the basin id (again working in the basins list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf744bf5-6ac9-404e-b6d5-1ba36030228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(basin):\n",
    "    return basin[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff9460c-6146-4bed-898e-74363fa37374",
   "metadata": {},
   "source": [
    "And we apply that function to all basins in the list; returning an ordered list of basin ids for using in a lookup. And again, this is a ***loop***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c69696-5b5e-4838-9360-5308e8624031",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [get_id(basin) for basin in basins]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c49003-1f6e-4c9d-bf13-46af7fa63ed8",
   "metadata": {},
   "source": [
    "Now, that we have these functions, we can describe the goal: constructing a square array where cell `[a,b]` is 1 if basin `b` drains into basin `a`, and otherwise is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f888f86-7dfc-4e76-9c2f-477a73df2db7",
   "metadata": {},
   "source": [
    "##### Step 2.1: make a square array with dimension matching the number of basins.\n",
    "Using the `identity` function in numpy, we can make this an identity matrix, which is a) square, b) has value zero everywhere except 1 on the diagonal. This is helpful because each basin flows into itself for the purpose of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc30dac-9e5f-4fcf-b8b3-5855ecb3580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "up = np.identity(len(basins))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45795659-717d-4f52-b594-2ae94198b99d",
   "metadata": {},
   "source": [
    "##### Step 2.2: use the `downs` list to set to 1 any `[a,b]` where basin `b` flows into basin `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25498aae-3583-4213-839f-0628e1e42c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(0,len(downs)):\n",
    "    if downs[d]!=0:\n",
    "        try:\n",
    "            up[ids.index(downs[d])][d]=1\n",
    "        except:\n",
    "            1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01bed83-8e06-4ed9-8a2a-87549c55766b",
   "metadata": {},
   "source": [
    "Now we have a square matrix showing all immediate upstream connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3b7b7-2d16-48b4-b55d-9a2aad033109",
   "metadata": {},
   "source": [
    "##### Step 2.3: Iterate through the matrix of immediate upstream connections to find basins upstream of upstream basins, basins upstream of basins upstream of upstream basins, etc\n",
    "\n",
    "This will consist of a function that pulls the indices of basins already known to be upstream and then many nested ***loops***, with enough nesting to work back through the network (based on our earlier network analysis, this appears to be 9, but we use 10 for good measure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60497761-8804-45a0-9ffe-06c023dcd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subit(z):\n",
    "    return [i for i, x in enumerate(up[z]) if x == 1]\n",
    "# Source of this syntax: https://stackoverflow.com/questions/57970751/python-what-does-i-for-i-mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3bfc6-97d8-4051-a11f-e9f76b6f4e4f",
   "metadata": {},
   "source": [
    "Now iterate back through the basin network, setting `up[a,b]=1` any time `b` ultimately flows to `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef4a7a-20a7-41f7-a433-fff6f7b001b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i0 in range(0,len(basins)):\n",
    "    x = list([i0])\n",
    "    i1 = subit(i0)\n",
    "    for z in i1:\n",
    "        x.append(z)\n",
    "        i2 = subit(z)\n",
    "        for z in i2:\n",
    "            x.append(z)\n",
    "            i3 = subit(z)\n",
    "            for z in i3:\n",
    "                x.append(z)\n",
    "                i4 = subit(z)\n",
    "                for z in i4:\n",
    "                    x.append(z)\n",
    "                    i5 = subit(z)\n",
    "                    for z in i5:\n",
    "                        x.append(z)\n",
    "                        i6 = subit(z)\n",
    "                        for z in i6:\n",
    "                            x.append(z)\n",
    "                            i7 = subit(z)\n",
    "                            for z in i7:\n",
    "                                x.append(z)\n",
    "                                i8 = subit(z)\n",
    "                                for z in i8:\n",
    "                                    x.append(z)\n",
    "                                    i9 = subit(z)\n",
    "                                    for z in i9:\n",
    "                                        x.append(z)\n",
    "                                        i10 = subit(z)\n",
    "                                        for z in i10:\n",
    "                                            x.append(z)\n",
    "    up[i0][x]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a5596c-2e7b-48a8-bc3a-52e9cd004387",
   "metadata": {},
   "source": [
    "To demonstrate the results, here is one of the rows, with zeros for basins that are not upstream and ones for basins that are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04499ad5-e8db-464c-9863-e8b9af8d577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "up[40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3895c-6e19-492a-a982-c2e8828a6f27",
   "metadata": {},
   "source": [
    "This means that basin #40 receives water from #40, #41, #42, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e50f9e8-d8df-476b-aefb-3d791a268324",
   "metadata": {},
   "source": [
    "With  connection matrix, we now know which basins ultimately flow into which other basins. The next step is to sum the burnt area in each basin upstream of a given basin and return the total burned area upstream (including the basin itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52711e6-7609-42ba-b7f0-b5bb159dfd91",
   "metadata": {},
   "source": [
    "##### Step 2.4: Find the total area burned in and upstream of each basin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa890f6a-5ad5-4bb0-ba3d-a58c39276f78",
   "metadata": {},
   "source": [
    "For each basin, we can sum up the burned area upstream by multiplity its row in the connection matrix by the entries in the burned list; the only burned areas that will participate in the sum are those that connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9daaba-51fc-4b22-9dce-69d1a7ea49e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_burnup(i):\n",
    "    return sum(np.multiply(up[i],burned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6317d47c-a7b5-434f-8bdf-f1ca1d7268f8",
   "metadata": {},
   "source": [
    "Next, we ***loop*** this for all basins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d21613-5a65-417a-ad39-5bc63a6581bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "burnup = [calc_burnup(i) for i in range(0,len(basins))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceeb728-f25d-48d0-a9dc-0ab8aaae51e3",
   "metadata": {},
   "source": [
    "This list `burnup` has the upstream burned area for each basin. Let's put that information back into the geodataframe and plot things!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f2118-5e53-42bf-92cc-cd8c52693537",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"burnup\"]=burnup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088279a-79ad-4447-9223-80c752c92ef0",
   "metadata": {},
   "source": [
    "Now, we can calculate the fraction of each basin's upstream area that has burned.\n",
    "*Note the need for a unit conversion for `UP_AREA` which must go from km$^2$ to m$^2$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e6bdf-a6c0-47a1-89cb-906074d5fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"fburnt\"]=b[\"burnup\"]/(b[\"UP_AREA\"]*1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b3cec0-eabf-4898-950a-7fae3a39d061",
   "metadata": {},
   "source": [
    "Now we can plot this, which should reveal the basins whose total water flow is most proportionately impacted by upstream fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f9f952-0251-4660-a910-4371aa6884f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.plot(column=\"fburnt\")\n",
    "plt.savefig(\"fburnt.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f6233f-45ab-4d8f-be6a-68490e126a1f",
   "metadata": {},
   "source": [
    "This map shows which basins are most vulnerable to fire-exacerbated discharge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac417a0-a776-4e18-a9c0-4ef3f5a97fbf",
   "metadata": {},
   "source": [
    "#### Step 3: Map fire-related discharge enchancement to current flood risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136486a-c5c8-450b-8cb6-e9268d7065bf",
   "metadata": {},
   "source": [
    "First, import the flood data (full credit to Hannah for finding and converting it to GeoJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c45660-f2bd-4578-a8c0-598cf7912945",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = gpd.read_file('data/flood_r.geojson').to_crs(epsg=6933)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead2b8c-0f0b-4f2f-a25d-b6135aa0912d",
   "metadata": {},
   "source": [
    "As above, convert the dataframe to a list using a ***loop***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84007109-c680-43f3-a483-6c77ba65d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "floods = []\n",
    "for i in list(range(0,d.shape[0])):\n",
    "    floods.append([d.iloc[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3894a316-f09b-4f0c-805b-ecffcb8520c7",
   "metadata": {},
   "source": [
    "Use a ***loop*** to make a new list of \"basins\" so the entries include the calculations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b91253-a670-4445-a9fe-54ae242220a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_basins = []\n",
    "for i in list(range(0,b.shape[0])):\n",
    "    new_basins.append([b.iloc[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd29c2-898f-496f-b819-ed463404edc4",
   "metadata": {},
   "source": [
    "As above, we need another triplet of functions. There are slightly different: we want to multiply each area of intersection (flood risk zone * enhanced basin) by the fire-exacerbated discharge enhancement for that basin. Also, this time we will just divide by basin area to scale it directly, rather than as a separate step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72618fc-d2d7-44f3-b4f4-e9b9890a1961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f4(a,b):\n",
    "    return (a[0][\"geometry\"].intersection(b[0][\"geometry\"])).area\n",
    "def f5(b,aa):\n",
    "    return sum([f4(a,b)*a[0][\"fburnt\"] for a in aa])\n",
    "def f6(aa,bb):\n",
    "    return [f5(b,aa)/b[0][\"geometry\"].area for b in bb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb4c3d-38be-4412-88c0-104467f5c6e8",
   "metadata": {},
   "source": [
    "Apply these functions to the basins and flood risks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e948418-64e2-4b3d-853b-2cddaf0e5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced=f6(new_basins,floods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a618e-fcfc-4201-97bd-1a38c982d4cc",
   "metadata": {},
   "source": [
    "And assign the resulting values to the flood zone dataframe, plot it to check, and save the graphic for the presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53338120-53c3-41ad-b24b-9786b2e26e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"enhanced\"]=enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78fae2-1f07-469d-afb6-961cafe31403",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.plot(column=\"enhanced\")\n",
    "plt.savefig(\"flood_enhance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15081d7b-4ca4-405a-84db-7ad7c9f680bf",
   "metadata": {},
   "source": [
    "#### Step 4: Allocate enhanced flood risks to census tracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece0282b-0722-4955-9459-a140dd2bbe01",
   "metadata": {},
   "source": [
    "Use a ***loop*** to make a new list of \"floods\" so the entries include the calculations above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2264f9-5258-49dc-bd41-6ca11c707d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_floods = []\n",
    "for i in list(range(0,d.shape[0])):\n",
    "    new_floods.append([d.iloc[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f3891-4563-40fe-a283-e3af1a2c671b",
   "metadata": {},
   "source": [
    "Impact census tract data (I'm using CalEnviroScreen as a handy source); as above, use a bounding box to narrow to LA county, and convert to the same coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ecdf9-c200-4004-8a07-7a3cf7fc17d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'data/calenviroscreen40shpf2021shp.zip'\n",
    "# Source: https://oehha.ca.gov/calenviroscreen/report/calenviroscreen-40\n",
    "bbox = (100000,-500000,225000,-350000)\n",
    "c = gpd.read_file(data_file,bbox=bbox).to_crs(epsg=6933)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f42e87-e0a5-4f4a-a3ce-24856b78738c",
   "metadata": {},
   "source": [
    "Filter for just tracts in LA County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6963800-ea6e-43d4-95f2-a52394dad071",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c[c['County']==\"Los Angeles\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff98b3e-e772-4441-ab2b-004d6e373e50",
   "metadata": {},
   "source": [
    "As above, use a ***loop*** to create a list \"tracts\" with one entry per tract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8708c2-b8ce-4db9-92b9-85d6143c5ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = []\n",
    "for i in list(range(0,c.shape[0])):\n",
    "    tracts.append([c.iloc[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cadd40-5994-40ed-9ea5-46e18c118a55",
   "metadata": {},
   "source": [
    "Here comes the third set of triplet functions. This is very similar to the last, just pulling the \"enhanced\" value from the flood risk instead of burnt fraction from the basins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce7fa3-22a3-47d1-a006-c99e33f540ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f7(a,b):\n",
    "    return (a[0][\"geometry\"].intersection(b[0][\"geometry\"])).area\n",
    "def f8(b,aa):\n",
    "    return sum([f7(a,b)*a[0][\"enhanced\"] for a in aa])\n",
    "def f9(aa,bb):\n",
    "    return [f8(b,aa) for b in bb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283f4e50-eaf6-4880-b5b1-916208fbc305",
   "metadata": {},
   "source": [
    "Apply this to the intersection of flood zones and census tracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0796941-d73f-4f5e-b1c0-4099481a64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "impact=f9(new_floods,tracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad6b26-52aa-48ba-9711-e42e42d7d748",
   "metadata": {},
   "source": [
    "As before, assign the outputs back to the geodataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8492380f-37b3-4e1b-b731-5f22c2354865",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"impact\"]=impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae2046-efe8-4744-9142-0954aafdb5d0",
   "metadata": {},
   "source": [
    "Find the area of each tract and standardize the `impact` values by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c0271-f4b8-454e-ba68-60faf3146c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = [tract[0][\"geometry\"].area for tract in tracts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c269bc-4dd2-488e-88df-633192871c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"area\"]=areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797b60b-851e-4a2b-8dcc-16bc710f04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"scaled_impact\"]=c[\"impact\"]/c[\"area\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511107f9-2fe1-489d-b7b0-f674fb95418c",
   "metadata": {},
   "source": [
    "Plot the data to check and also make the graphic for the presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb664bc-cdf2-4876-9a4b-8916ce079a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.plot(column=\"scaled_impact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f0531e-2d9d-4772-98e1-78edb980695d",
   "metadata": {},
   "source": [
    "These are the census tracts in LA County with flood risk whose risk is most sensitive to fire-exacerbation, prior to incorporating population vulnerability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb213752-32b8-41c3-9b57-fe7ed457b57e",
   "metadata": {},
   "source": [
    "#### Step 5: Integrate with social vulnerability scores\n",
    "\n",
    "Here we are using CalEnviroScreen (already imported!); ultimate we will use a superior social vulnerability metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ae34e8-d7c2-46ee-93e3-5c2a43e16988",
   "metadata": {},
   "source": [
    "Construct a column of scaled \"fire enhanced flood\" impact *times* CalEnviroScreen score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74944b18-2baa-41bf-aa70-a4864dd60308",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"FEFxCES\"]=c[\"scaled_impact\"]*c[\"CIscoreP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e7bbc-dfd6-4dd1-8eff-f6aa98a190f8",
   "metadata": {},
   "source": [
    "Drop tracts without scores and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfcfb2-dab8-4816-b251-b899461005dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c[c[\"CIscoreP\"]>0].plot(column=\"FEFxCES\")\n",
    "plt.savefig(\"fefxces.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a8c84-a91c-4cf8-b5f9-9e998c2ff752",
   "metadata": {},
   "source": [
    "This map suggests census tracts with flood risk that have high combinations of social vulnerability and fraction of upstream land has historically burned. Flood risk in these tracts perhaps should be re-evaluated in light of the potential for upstream burning to enhance water discharge and flood protection and resilience measures may be particularly valuable in these areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b32dc58-d137-4599-9722-d70ce7bb9bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
